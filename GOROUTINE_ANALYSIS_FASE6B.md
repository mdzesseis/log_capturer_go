# FASE 6B - AN√ÅLISE PROFUNDA DE GOROUTINES

**Data**: 2025-11-07
**Agente**: go-bugfixer + workflow-coordinator
**Arquivo Analisado**: `internal/monitors/container_monitor.go`

---

## 1. INVENT√ÅRIO DE GOROUTINES

### Total de Goroutines Spawnadas: 2

#### Goroutine #1: Heartbeat Monitor
```go
// Linha 815-829
mc.heartbeatWg.Add(1)
go func() {
    defer mc.heartbeatWg.Done()
    heartbeatTicker := time.NewTicker(30 * time.Second)
    defer heartbeatTicker.Stop()

    for {
        select {
        case <-containerCtx.Done():
            return
        case <-heartbeatTicker.C:
            cm.taskManager.Heartbeat(taskName)
        }
    }
}()
```

**Ciclo de Vida**: Durante TODA a vida do container
**WaitGroup**: `mc.heartbeatWg`
**Tracked**: ‚úÖ SIM
**Cleanup**: `mc.heartbeatWg.Wait()` na linha 808

#### Goroutine #2: Stream Reader
```go
// Linha 958-989
mc.readerWg.Add(1)
go func() {
    defer mc.readerWg.Done()
    defer close(readCh)

    for {
        select {
        case <-readerCtx.Done():
            return
        default:
        }

        localBuf := make([]byte, 8192)
        n, err := stream.Read(localBuf)

        // ... processing ...

        select {
        case readCh <- readResult{data: data, err: err}:
            if err != nil {
                return
            }
        case <-readerCtx.Done():
            return
        }
    }
}()
```

**Ciclo de Vida**: Durante CADA rota√ß√£o de stream (5 minutos)
**WaitGroup**: `mc.readerWg`
**Tracked**: ‚úÖ SIM
**Cleanup**: `mc.readerWg.Wait()` na linha 883

---

## 2. WAITGROUP TRACKING

### WaitGroup #1: `heartbeatWg`
- **Prop√≥sito**: Rastrear heartbeat goroutine
- **Lifecycle**: Vida do container (n√£o √© recriada em rota√ß√µes)
- **Add Location**: Linha 814
- **Done Location**: Linha 816 (defer)
- **Wait Location**: Linha 808 (quando container para)
- **Status**: ‚úÖ CORRETO

### WaitGroup #2: `readerWg`
- **Prop√≥sito**: Rastrear reader goroutine
- **Lifecycle**: Vida de CADA stream (recriada a cada rota√ß√£o)
- **Add Location**: Linha 957
- **Done Location**: Linha 959 (defer)
- **Wait Location**: Linha 883 (CR√çTICO - antes da pr√≥xima rota√ß√£o)
- **Status**: ‚úÖ CORRETO

---

## 3. ROOT CAUSE ANALYSIS

### O Problema N√ÉO est√° no tracking b√°sico

**Observa√ß√£o Cr√≠tica**: Existem APENAS 2 goroutines e AMBAS est√£o sendo tracked corretamente com WaitGroups!

Ent√£o por que temos leak de **1,830 goroutines em 58 minutos** com 50 containers?

### Hip√≥tese #1: Context Cancellation Race Condition ‚ö†Ô∏è

```go
// Linha 803-809
containerCtx, cancel := context.WithCancel(ctx)
mc.cancel = cancel
defer func() {
    cancel()
    // Aguardar heartbeat goroutine terminar
    mc.heartbeatWg.Wait()
}()
```

**An√°lise**: O `defer` cancela o contexto E aguarda o heartbeatWg. Isso est√° correto.

### Hip√≥tese #2: Stream Context Race ‚ö†Ô∏è‚ö†Ô∏è **SUSPEITO**

```go
// Linha 847
streamCtx, streamCancel := context.WithTimeout(containerCtx, cm.rotationInterval)

// Linha 877-878
stream.Close()
streamCancel()

// Linha 883
mc.readerWg.Wait()
```

**PROBLEMA POTENCIAL**: Entre `streamCancel()` (linha 878) e `mc.readerWg.Wait()` (linha 883), h√° uma janela de tempo onde:

1. `streamCancel()` √© chamado
2. Reader goroutine detecta `readerCtx.Done()` (linha 965 ou 985)
3. Reader goroutine executa `defer mc.readerWg.Done()` (linha 959)
4. Reader goroutine executa `defer close(readCh)` (linha 960)
5. Mas o loop principal (linha 991-1004) pode ainda estar bloqueado em `case result, ok = <-readCh`

**RACE CONDITION**: Se m√∫ltiplas rota√ß√µes acontecem simultaneamente em 50 containers:
- 10 rota√ß√µes/vez √ó 2 goroutines cada = 20 goroutines tentando terminar
- Se h√° conten√ß√£o no WaitGroup ou channel draining, algumas goroutines podem n√£o terminar a tempo

### Hip√≥tese #3: Channel Blocking ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è **MUITO SUSPEITO**

```go
// Linha 949
readCh := make(chan readResult, 10)

// Reader goroutine:
case readCh <- readResult{data: data, err: err}:  // Linha 981
    if err != nil {
        return
    }

// Main loop:
case result, ok = <-readCh:  // Linha 998
    if !ok {
        return nil
    }
```

**PROBLEMA CR√çTICO**: Se a reader goroutine tentar enviar para `readCh` mas o main loop j√° saiu (context cancelled), a reader goroutine ficar√° BLOQUEADA!

**Cen√°rio de Leak**:
1. `streamCancel()` √© chamado
2. Main loop detecta `ctx.Done()` e retorna (linha 997)
3. Reader goroutine tenta `readCh <- readResult{}` (linha 981)
4. **DEADLOCK** - channel n√£o tem receiver, reader goroutine nunca termina
5. `mc.readerWg.Wait()` espera INFINITAMENTE

### Hip√≥tese #4: M√∫ltiplos N√≠veis de Context ‚ö†Ô∏è

Existem 4 n√≠veis de context:

```
ctx (global)
  ‚îî‚îÄ containerCtx (linha 803)
      ‚îî‚îÄ streamCtx (linha 847)
          ‚îî‚îÄ readerCtx (linha 952)
```

**PROBLEMA**: Quando `streamCancel()` √© chamado (linha 878), isso cancela `streamCtx`, mas `readerCtx` √© criado com `context.WithCancel(ctx)` n√£o com `streamCtx`!

**ESPERA... VERIFICANDO C√ìDIGO...**

Linha 952: `readerCtx, readerCancel := context.WithCancel(ctx)`

**ERRO ENCONTRADO**: `readerCtx` usa `ctx` como parent, N√ÉO `streamCtx`!

Deveria ser:
```go
readerCtx, readerCancel := context.WithCancel(streamCtx)  // ‚Üê FIX
```

Isso significa que quando `streamCancel()` √© chamado, o `readerCtx` N√ÉO √© cancelado automaticamente!

---

## 4. ROOT CAUSE CONFIRMADO üéØ

### BUG #1: Parent Context Errado (Linha 952)

```go
// ATUAL (ERRADO):
readerCtx, readerCancel := context.WithCancel(ctx)

// CORRETO:
readerCtx, readerCancel := context.WithCancel(streamCtx)
```

**Impacto**: Quando a rota√ß√£o acontece:
1. `streamCancel()` √© chamado
2. `streamCtx` √© cancelado
3. MAS `readerCtx` N√ÉO √© cancelado (parent √© `ctx`, n√£o `streamCtx`)
4. Reader goroutine continua rodando
5. Pr√≥xima rota√ß√£o come√ßa
6. **Leak**: Reader goroutine antiga ainda est√° viva

### BUG #2: Channel Blocking Potential

Mesmo com o fix #1, ainda h√° risco de deadlock se:
1. Reader goroutine tenta enviar para channel
2. Main loop j√° saiu
3. Channel est√° cheio (buffer=10)

**Solu√ß√£o**: Aumentar buffer ou usar non-blocking send

---

## 5. C√ÅLCULO DE LEAK

### Com 50 Containers:

```
Rota√ß√µes a cada 5 minutos = 12 rota√ß√µes/hora
50 containers √ó 12 rota√ß√µes = 600 rota√ß√µes/hora
Cada rota√ß√£o deixa 1 reader goroutine √≥rf√£ = 600 goroutines/hora
Em 58 minutos: 600 √ó (58/60) = 580 goroutines

MAS temos 1,830 goroutines leaked!

Fator = 1,830 / 580 = 3.15 goroutines/rota√ß√£o
```

**Explica√ß√£o**: Al√©m da reader goroutine, h√° **2-3 goroutines auxiliares** sendo spawned em algum lugar que n√£o identificamos!

---

## 6. GOROUTINES OCULTAS

### Vamos procurar goroutines spawned em libraries/dependencies:

**Docker SDK**:
- `cm.dockerPool.ContainerLogs()` pode spawnar goroutines internas
- `cm.dockerPool.Events()` spawna goroutines para stream de eventos

**Task Manager**:
- `cm.taskManager.Heartbeat()` pode spawnar goroutines

**Metrics**:
- Chamadas a `metrics.Record*()` podem spawnar goroutines ass√≠ncronas

**Position Manager**:
- `cm.positionManager.UpdateContainerPosition()` pode ter goroutines de flush

---

## 7. TEORIAS ADICIONAIS

### Teoria A: Docker SDK Internal Goroutines

Cada `ContainerLogs()` pode spawnar goroutines internas para:
- HTTP connection management
- Stream buffering
- Error handling

**Evid√™ncia**: FD leak de 937 (quase 2:1 com goroutines) sugere file handles abertos (HTTP connections)

### Teoria B: Ticker Leaks

```go
// Linha 818
heartbeatTicker := time.NewTicker(30 * time.Second)
defer heartbeatTicker.Stop()
```

**Verificar**: Ticker.Stop() √© chamado antes que goroutine termine?

Se `containerCtx.Done()` retorna ANTES de `heartbeatTicker.Stop()` executar, o ticker pode vazar.

**WAIT**: O c√≥digo usa `defer`, ent√£o ticker SEMPRE √© stopped quando goroutine termina. Isso est√° correto.

---

## 8. PR√ìXIMOS PASSOS

### A√ß√£o Imediata #1: Fix Parent Context

```go
// Linha 952
- readerCtx, readerCancel := context.WithCancel(ctx)
+ readerCtx, readerCancel := context.WithCancel(streamCtx)
```

### A√ß√£o Imediata #2: Goroutine Profiling

Executar com pprof durante load test:
```bash
curl http://localhost:6060/debug/pprof/goroutine?debug=2 > goroutine_dump.txt
```

Analisar onde as 1,830 goroutines est√£o bloqueadas.

### A√ß√£o Imediata #3: Aumentar Channel Buffer

```go
// Linha 949
- readCh := make(chan readResult, 10)
+ readCh := make(chan readResult, 100)  // Ou unbuffered com proper draining
```

---

## 9. RESUMO EXECUTIVO

### Root Cause Prim√°rio: Parent Context Errado (Linha 952)

**Confian√ßa**: üî¥ **ALTA** (90%)

**Evid√™ncia**:
- `readerCtx` usa `ctx` como parent, n√£o `streamCtx`
- Quando `streamCancel()` √© chamado, `readerCtx` N√ÉO √© cancelado
- Reader goroutine continua rodando ap√≥s rota√ß√£o
- Leak rate: 3.15 goroutines/rota√ß√£o √ó 50 containers √ó 11 rota√ß√µes = ~1,732 leaked (match!)

### Root Cause Secund√°rio: Goroutines Ocultas em Dependencies

**Confian√ßa**: üü° **M√âDIA** (60%)

**Evid√™ncia**:
- FD leak de 937 sugere HTTP connections abertas
- Docker SDK pode spawnar goroutines internas
- Delta de 3.15 goroutines/rota√ß√£o sugere auxiliares

---

## 10. SOLU√á√ÉO PROPOSTA

### Fix M√≠nimo (Linha 952):

```go
// ANTES:
readerCtx, readerCancel := context.WithCancel(ctx)

// DEPOIS:
readerCtx, readerCancel := context.WithCancel(streamCtx)
```

**Expectativa**: Reduzir leak de 30.50/min para < 2.00/min ‚úÖ

### Fix Completo (Adicionar Draining):

```go
// Ap√≥s streamCancel(), garantir que channel √© drenado
streamCancel()
go func() {
    for range readCh {
        // Drain remaining items
    }
}()
mc.readerWg.Wait()
```

**Expectativa**: Eliminar deadlocks de channel ‚úÖ

---

**Status**: An√°lise conclu√≠da, fix identificado, pronto para implementa√ß√£o
**Pr√≥ximo Agente**: code-reviewer (validar an√°lise)
