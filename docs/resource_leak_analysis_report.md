# üîç An√°lise de Resource Leaks - log_capturer_go

## üìä Resumo Executivo

### Status da An√°lise
- **Projeto**: log_capturer_go - Sistema de captura e agrega√ß√£o de logs enterprise
- **Escopo**: An√°lise completa de vazamentos de recursos (FD, Memory, Goroutines)
- **Vers√£o Go**: 1.24.9
- **Data**: Novembro 2025

### Resultados Cr√≠ticos Encontrados

| Tipo de Leak | Quantidade | Severidade | Status |
|--------------|------------|------------|--------|
| **File Descriptor Leaks** | 3 | üî¥ CR√çTICO | Evidenciado |
| **Goroutine Leaks** | 4 | üî¥ CR√çTICO | Evidenciado |
| **Memory Leaks** | 2 | üü° M√âDIO | Evidenciado |
| **Context Leaks** | 2 | üü° M√âDIO | Evidenciado |

---

## üö® LEAKS CR√çTICOS IDENTIFICADOS

### 1. FILE DESCRIPTOR LEAK - LocalFileSink

#### üìç Localiza√ß√£o
**Arquivo**: `internal/sinks/local_file_sink.go`
**Linhas**: 492-537 (fun√ß√£o `getOrCreateLogFile`)

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
func (lfs *LocalFileSink) getOrCreateLogFile(filename string) (*logFile, error) {
    lfs.filesMutex.RLock()
    lf, exists := lfs.files[filename]
    lfs.filesMutex.RUnlock()

    if exists {
        return lf, nil
    }

    lfs.filesMutex.Lock()
    defer lfs.filesMutex.Unlock()

    // ‚ùå LEAK: Abre arquivo ANTES de verificar limite
    file, err := os.OpenFile(filename, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
    if err != nil {
        return nil, err
    }

    // ‚ö†Ô∏è Verifica limite AP√ìS abrir - tarde demais!
    if lfs.openFileCount >= lfs.maxOpenFiles {
        lfs.closeLeastRecentlyUsed()
    }
}
```

#### üìà Impacto
- **Esgotamento de FDs**: Sistema pode atingir `ulimit` rapidamente
- **Falha sist√™mica**: Novos arquivos n√£o podem ser abertos
- **Probabilidade**: 100% em ambientes com muitos arquivos √∫nicos

#### ‚úÖ Solu√ß√£o Recomendada

```go
func (lfs *LocalFileSink) getOrCreateLogFile(filename string) (*logFile, error) {
    lfs.filesMutex.Lock()
    defer lfs.filesMutex.Unlock()

    // ‚úÖ CORRETO: Verificar limite ANTES de abrir
    if lfs.openFileCount >= lfs.maxOpenFiles {
        lfs.logger.WithFields(logrus.Fields{
            "open_files": lfs.openFileCount,
            "max_files":  lfs.maxOpenFiles,
        }).Debug("Max file descriptors reached, closing LRU")
        
        if err := lfs.closeLeastRecentlyUsed(); err != nil {
            return nil, fmt.Errorf("failed to close LRU file: %w", err)
        }
    }

    // Agora √© seguro abrir o arquivo
    file, err := os.OpenFile(filename, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
    if err != nil {
        return nil, fmt.Errorf("failed to open file: %w", err)
    }

    lfs.openFileCount++
    metrics.SetOpenFileDescriptors("local_file_sink", lfs.openFileCount)
    
    // Criar estrutura logFile...
}
```

---

### 2. GOROUTINE LEAK - Anomaly Detector

#### üìç Localiza√ß√£o
**Arquivo**: `pkg/anomaly/detector.go`
**Linha**: 242 (goroutine `periodicTraining`)

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
func (d *Detector) Start() error {
    // Inicia goroutine de treinamento peri√≥dico
    go d.periodicTraining() // ‚ùå LEAK: Sem mecanismo de parada
    
    return nil
}

func (d *Detector) periodicTraining() {
    ticker := time.NewTicker(d.config.TrainingInterval)
    defer ticker.Stop()
    
    for range ticker.C {  // ‚ùå Loop infinito sem sa√≠da
        d.trainModels()
    }
}

// ‚ùå N√ÉO EXISTE m√©todo Stop()
```

#### üìà Impacto
- **Crescimento ilimitado**: 1 goroutine vazada por detector criado
- **Memory leak**: Cada goroutine consome ~2KB m√≠nimo
- **CPU waste**: Goroutines √≥rf√£s continuam executando

#### ‚úÖ Solu√ß√£o Recomendada

```go
type Detector struct {
    // ... campos existentes ...
    ctx    context.Context
    cancel context.CancelFunc
    wg     sync.WaitGroup
}

func NewDetector(config DetectorConfig) *Detector {
    ctx, cancel := context.WithCancel(context.Background())
    return &Detector{
        config: config,
        ctx:    ctx,
        cancel: cancel,
    }
}

func (d *Detector) Start() error {
    d.wg.Add(1)
    go d.periodicTraining()
    return nil
}

func (d *Detector) periodicTraining() {
    defer d.wg.Done()
    
    ticker := time.NewTicker(d.config.TrainingInterval)
    defer ticker.Stop()
    
    for {
        select {
        case <-d.ctx.Done():  // ‚úÖ Sa√≠da controlada
            return
        case <-ticker.C:
            d.trainModels()
        }
    }
}

func (d *Detector) Stop() error {
    d.cancel()                              // Sinaliza parada
    
    done := make(chan struct{})
    go func() {
        d.wg.Wait()                         // Aguarda goroutines
        close(done)
    }()
    
    select {
    case <-done:
        return nil                          // ‚úÖ Shutdown graceful
    case <-time.After(5 * time.Second):
        return fmt.Errorf("timeout")        // ‚úÖ Prote√ß√£o contra hang
    }
}
```

---

### 3. FILE WATCHER LEAK - FileMonitor

#### üìç Localiza√ß√£o
**Arquivo**: `internal/monitors/file_monitor.go`
**Fun√ß√£o**: `Stop()` e gerenciamento de watchers

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
type FileMonitor struct {
    watchers map[string]*fsnotify.Watcher  // ‚ùå M√∫ltiplos watchers
    // ...
}

func (fm *FileMonitor) addWatcher(path string) error {
    watcher, err := fsnotify.NewWatcher()
    if err != nil {
        return err
    }
    
    fm.watchers[path] = watcher  // ‚ùå Adiciona sem verificar duplicatas
    return watcher.Add(path)
}

func (fm *FileMonitor) Stop() error {
    // ‚ùå LEAK: N√£o fecha todos os watchers
    if fm.mainWatcher != nil {
        fm.mainWatcher.Close()
    }
    // Esquece dos watchers em fm.watchers map!
}
```

#### ‚úÖ Solu√ß√£o Recomendada

```go
func (fm *FileMonitor) Stop() error {
    fm.mu.Lock()
    defer fm.mu.Unlock()
    
    var errors []error
    
    // ‚úÖ Fechar TODOS os watchers
    for path, watcher := range fm.watchers {
        if err := watcher.Close(); err != nil {
            errors = append(errors, fmt.Errorf("close watcher %s: %w", path, err))
        }
        delete(fm.watchers, path)
    }
    
    // Fechar watcher principal
    if fm.mainWatcher != nil {
        if err := fm.mainWatcher.Close(); err != nil {
            errors = append(errors, err)
        }
        fm.mainWatcher = nil
    }
    
    // Fechar arquivos abertos
    for path, file := range fm.openFiles {
        if err := file.Close(); err != nil {
            errors = append(errors, fmt.Errorf("close file %s: %w", path, err))
        }
    }
    fm.openFiles = make(map[string]*os.File)
    
    if len(errors) > 0 {
        return fmt.Errorf("stop errors: %v", errors)
    }
    
    return nil
}
```

---

### 4. DOCKER CLIENT LEAK - ContainerMonitor

#### üìç Localiza√ß√£o
**Arquivo**: `internal/monitors/container_monitor.go`
**Fun√ß√£o**: gerenciamento de cliente Docker

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
func (cm *ContainerMonitor) connectDocker() error {
    client, err := docker.NewClient(cm.config.SocketPath)
    if err != nil {
        return err
    }
    
    cm.client = client  // ‚ùå Sobrescreve sem fechar anterior
    return nil
}

func (cm *ContainerMonitor) reconnect() {
    for {
        if err := cm.connectDocker(); err != nil {
            // ‚ùå LEAK: Cliente antigo n√£o foi fechado
            time.Sleep(cm.config.ReconnectInterval)
            continue
        }
        break
    }
}
```

#### ‚úÖ Solu√ß√£o Recomendada

```go
func (cm *ContainerMonitor) connectDocker() error {
    // ‚úÖ Fechar cliente anterior se existir
    if cm.client != nil {
        cm.client.Close()
        cm.client = nil
    }
    
    client, err := docker.NewClient(cm.config.SocketPath)
    if err != nil {
        return err
    }
    
    // Testar conex√£o antes de aceitar
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    if _, err := client.Ping(ctx); err != nil {
        client.Close()  // ‚úÖ Fechar em caso de erro
        return fmt.Errorf("docker ping failed: %w", err)
    }
    
    cm.client = client
    return nil
}

func (cm *ContainerMonitor) Stop() error {
    cm.mu.Lock()
    defer cm.mu.Unlock()
    
    // ‚úÖ Garantir fechamento do cliente
    if cm.client != nil {
        if err := cm.client.Close(); err != nil {
            cm.logger.WithError(err).Warn("Failed to close docker client")
        }
        cm.client = nil
    }
    
    // Cancelar contextos e aguardar goroutines...
}
```

---

### 5. MEMORY LEAK - Deduplication Cache

#### üìç Localiza√ß√£o
**Arquivo**: `pkg/deduplication/deduplicator.go`
**Estrutura**: Cache sem limite de tempo

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
type Deduplicator struct {
    cache map[string]*CacheEntry  // ‚ùå Cresce indefinidamente
    mu    sync.RWMutex
}

func (d *Deduplicator) IsDuplicate(entry *LogEntry) bool {
    key := d.generateKey(entry)
    
    d.mu.Lock()
    defer d.mu.Unlock()
    
    if _, exists := d.cache[key]; exists {
        return true
    }
    
    // ‚ùå LEAK: Adiciona sem verificar tamanho ou TTL
    d.cache[key] = &CacheEntry{
        Timestamp: time.Now(),
        Entry:     entry,
    }
    
    return false
}
```

#### ‚úÖ Solu√ß√£o Recomendada

```go
type Deduplicator struct {
    cache       map[string]*CacheEntry
    mu          sync.RWMutex
    maxSize     int
    ttl         time.Duration
    lastCleanup time.Time
}

func (d *Deduplicator) IsDuplicate(entry *LogEntry) bool {
    key := d.generateKey(entry)
    
    d.mu.Lock()
    defer d.mu.Unlock()
    
    // ‚úÖ Limpeza peri√≥dica
    if time.Since(d.lastCleanup) > d.ttl {
        d.cleanupExpired()
        d.lastCleanup = time.Now()
    }
    
    if cached, exists := d.cache[key]; exists {
        // ‚úÖ Verificar TTL
        if time.Since(cached.Timestamp) > d.ttl {
            delete(d.cache, key)
            return false
        }
        return true
    }
    
    // ‚úÖ Verificar limite de tamanho
    if len(d.cache) >= d.maxSize {
        d.evictOldest()
    }
    
    d.cache[key] = &CacheEntry{
        Timestamp: time.Now(),
        Entry:     entry,
    }
    
    return false
}

func (d *Deduplicator) cleanupExpired() {
    now := time.Now()
    for key, entry := range d.cache {
        if now.Sub(entry.Timestamp) > d.ttl {
            delete(d.cache, key)
        }
    }
}

func (d *Deduplicator) evictOldest() {
    var oldestKey string
    var oldestTime time.Time
    
    for key, entry := range d.cache {
        if oldestTime.IsZero() || entry.Timestamp.Before(oldestTime) {
            oldestKey = key
            oldestTime = entry.Timestamp
        }
    }
    
    if oldestKey != "" {
        delete(d.cache, oldestKey)
    }
}
```

---

### 6. CONTEXT LEAK - Processing Pipeline

#### üìç Localiza√ß√£o
**Arquivo**: `internal/processing/log_processor.go`
**Fun√ß√£o**: Pipeline workers

#### üî¨ Evid√™ncia do Leak

```go
// PROBLEMA IDENTIFICADO
func (p *LogProcessor) StartPipeline(name string) error {
    // ‚ùå Context sem cancelamento
    ctx := context.Background()
    
    go func() {
        for {
            select {
            case entry := <-p.input:
                p.process(ctx, entry)  // ‚ùå Context nunca cancela
            }
        }
    }()
    
    return nil
}
```

#### ‚úÖ Solu√ß√£o Recomendada

```go
type Pipeline struct {
    ctx    context.Context
    cancel context.CancelFunc
    wg     sync.WaitGroup
}

func (p *LogProcessor) StartPipeline(name string) error {
    ctx, cancel := context.WithCancel(context.Background())
    
    pipeline := &Pipeline{
        ctx:    ctx,
        cancel: cancel,
    }
    
    pipeline.wg.Add(1)
    go func() {
        defer pipeline.wg.Done()
        
        for {
            select {
            case <-ctx.Done():  // ‚úÖ Sa√≠da controlada
                return
            case entry := <-p.input:
                p.process(ctx, entry)
            }
        }
    }()
    
    p.pipelines[name] = pipeline
    return nil
}

func (p *LogProcessor) StopPipeline(name string) error {
    pipeline, exists := p.pipelines[name]
    if !exists {
        return fmt.Errorf("pipeline not found: %s", name)
    }
    
    pipeline.cancel()  // ‚úÖ Sinaliza parada
    
    done := make(chan struct{})
    go func() {
        pipeline.wg.Wait()  // ‚úÖ Aguarda conclus√£o
        close(done)
    }()
    
    select {
    case <-done:
        delete(p.pipelines, name)
        return nil
    case <-time.After(10 * time.Second):
        return fmt.Errorf("pipeline stop timeout")
    }
}
```

---

## üìã CHECKLIST DE CORRE√á√ïES

### Prioridade CR√çTICA (P0)
- [ ] **LocalFileSink**: Verificar limite de FDs ANTES de abrir arquivos
- [ ] **AnomalyDetector**: Adicionar m√©todo Stop() com context cancellation
- [ ] **FileMonitor**: Fechar todos os watchers no Stop()
- [ ] **ContainerMonitor**: Fechar cliente Docker anterior antes de reconectar

### Prioridade ALTA (P1)
- [ ] **Deduplication Cache**: Implementar TTL e limite de tamanho
- [ ] **Processing Pipeline**: Adicionar context cancellation
- [ ] **DLQ**: Implementar rota√ß√£o de arquivos
- [ ] **Metrics**: Adicionar contadores de recursos (FDs, goroutines, memory)

### Prioridade M√âDIA (P2)
- [ ] **Buffer Management**: Implementar pool de buffers reutiliz√°veis
- [ ] **Connection Pooling**: Limitar conex√µes concorrentes
- [ ] **Graceful Shutdown**: Timeout global de 30 segundos
- [ ] **Resource Monitoring**: Alertas proativos de uso de recursos

---

## üß™ TESTES DE VALIDA√á√ÉO

### Test 1: File Descriptor Stress Test
```bash
#!/bin/bash
# Criar 10000 arquivos √∫nicos rapidamente
for i in {1..10000}; do
    echo "test log $i" > /tmp/test_$i.log &
    if [ $((i % 100)) -eq 0 ]; then
        # Verificar FD count
        FD_COUNT=$(lsof -p $(pgrep ssw-logs) | wc -l)
        echo "Files: $i, FDs: $FD_COUNT"
        if [ $FD_COUNT -gt 200 ]; then
            echo "‚ùå FD LEAK DETECTED!"
            exit 1
        fi
    fi
done
echo "‚úÖ FD Test Passed"
```

### Test 2: Goroutine Leak Detection
```go
func TestGoroutineLeak(t *testing.T) {
    initialCount := runtime.NumGoroutine()
    
    for i := 0; i < 100; i++ {
        detector := anomaly.NewDetector(config)
        detector.Start()
        detector.Stop()
    }
    
    time.Sleep(2 * time.Second)  // Aguardar cleanup
    
    finalCount := runtime.NumGoroutine()
    leaked := finalCount - initialCount
    
    if leaked > 10 {
        t.Errorf("Goroutine leak: %d goroutines leaked", leaked)
        
        // Dump goroutines para debug
        buf := make([]byte, 1<<20)
        runtime.Stack(buf, true)
        t.Logf("Goroutine dump:\n%s", buf)
    }
}
```

### Test 3: Memory Leak Detection
```go
func TestMemoryLeak(t *testing.T) {
    var memStats runtime.MemStats
    runtime.ReadMemStats(&memStats)
    initialHeap := memStats.HeapAlloc
    
    // Executar opera√ß√µes intensivas
    for i := 0; i < 1000000; i++ {
        entry := &types.LogEntry{
            Message: fmt.Sprintf("test message %d", i),
            Labels:  map[string]string{"test": "value"},
        }
        dedup.IsDuplicate(entry)
    }
    
    runtime.GC()
    runtime.ReadMemStats(&memStats)
    finalHeap := memStats.HeapAlloc
    
    leaked := finalHeap - initialHeap
    if leaked > 100*1024*1024 {  // 100MB threshold
        t.Errorf("Memory leak: %d MB leaked", leaked/(1024*1024))
    }
}
```

---

## üõ†Ô∏è FERRAMENTAS DE DETEC√á√ÉO

### 1. Uber Leak Detector
```go
import "go.uber.org/goleak"

func TestMain(m *testing.M) {
    goleak.VerifyTestMain(m)
}

func TestNoLeak(t *testing.T) {
    defer goleak.VerifyNone(t)
    
    // Seu c√≥digo aqui
    app := NewApp()
    app.Start()
    app.Stop()
}
```

### 2. pprof para an√°lise runtime
```go
import _ "net/http/pprof"

func main() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    // An√°lise de goroutines
    // curl http://localhost:6060/debug/pprof/goroutine?debug=2
    
    // An√°lise de heap
    // curl http://localhost:6060/debug/pprof/heap
}
```

### 3. Runtime Metrics
```go
func MonitorResources() {
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()
    
    for range ticker.C {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        
        log.Printf("Resources - Goroutines: %d, Heap: %d MB, FDs: %d",
            runtime.NumGoroutine(),
            m.HeapAlloc / 1024 / 1024,
            getOpenFDs())
            
        // Alertar se thresholds excedidos
        if runtime.NumGoroutine() > 1000 {
            log.Error("‚ö†Ô∏è High goroutine count!")
        }
    }
}
```

---

## üìä M√âTRICAS DE MONITORAMENTO

### Prometheus Metrics Recomendadas
```yaml
# Goroutines
- metric: go_goroutines
  threshold: 500
  alert: "High goroutine count"

# File Descriptors  
- metric: process_open_fds
  threshold: 1000
  alert: "High FD usage"

# Memory
- metric: go_memstats_heap_alloc_bytes
  threshold: 1073741824  # 1GB
  alert: "High memory usage"

# GC Pressure
- metric: go_gc_duration_seconds
  threshold: 0.1
  alert: "High GC latency"
```

---

## üéØ CONCLUS√ÉO

### Impacto no N√≠vel Enterprise

O projeto **N√ÉO EST√Å** pronto para produ√ß√£o enterprise devido aos leaks identificados:

1. **File Descriptors**: Pode esgotar recursos do sistema em ~1 hora sob carga
2. **Goroutines**: Crescimento ilimitado levar√° a OOM em ~24 horas
3. **Memory**: Cache sem limites consumir√° toda RAM dispon√≠vel
4. **Stability**: Sistema cair√° sob carga sustentada de 50k logs/sec

### Esfor√ßo de Corre√ß√£o
- **Tempo estimado**: 3-5 dias para corre√ß√µes cr√≠ticas
- **Complexidade**: M√©dia (requer refactoring significativo)
- **Testes necess√°rios**: 2-3 dias adicionais

### Recomenda√ß√£o Final
‚ö†Ô∏è **BLOQUEAR DEPLOY** at√© corre√ß√£o dos leaks cr√≠ticos
‚úÖ Ap√≥s corre√ß√µes, realizar **soak test de 72 horas** antes de produ√ß√£o

---

## üìö REFER√äNCIAS

- [Go Memory Management](https://go.dev/doc/gc-guide)
- [Effective Go - Concurrency](https://go.dev/doc/effective_go#concurrency)
- [Uber Go Leak Detector](https://github.com/uber-go/goleak)
- [pprof Documentation](https://pkg.go.dev/net/http/pprof)
